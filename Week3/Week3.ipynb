{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77688027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# Title: Assignment 3.2\n",
    "# Author: Surenther Selvaraj\n",
    "# Date: 26 September 2025\n",
    "# Modified By: Surenther Selvaraj\n",
    "# Description: Sentiment Analysis and Preprocessing Text\n",
    "# Data: https://www.kaggle.com/c/word2vec-nlp-tutorial/data\n",
    "# ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03c54f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Importing Libraries ---\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b8aa834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the DataFrame:\n",
      "       id  sentiment                                             review\n",
      "0  5814_8          1  With all this stuff going down at the moment w...\n",
      "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
      "3  3630_4          0  It must be assumed that those who praised this...\n",
      "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...\n"
     ]
    }
   ],
   "source": [
    "#Import the movie review data\n",
    "\n",
    "# The name of the file\n",
    "file_name = \"labeledTrainData.tsv\"\n",
    "\n",
    "# Using pandas.read_csv with the correct delimiter for a .tsv file\n",
    "df = pd.read_csv(file_name, sep='\\t')\n",
    "\n",
    "# Check if the data is loaded properly by displaying the first few rows\n",
    "print(\"\\nFirst 5 rows of the DataFrame:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc7be67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive and negative reviews:\n",
      "Positive Reviews (1): 12500\n",
      "Negative Reviews (0): 12500\n"
     ]
    }
   ],
   "source": [
    "# Count the number of positive and negative reviews\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "\n",
    "# Print the results with clear labels\n",
    "print(\"Number of positive and negative reviews:\")\n",
    "print(f\"Positive Reviews (1): {sentiment_counts[1]}\")\n",
    "print(f\"Negative Reviews (0): {sentiment_counts[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e82813d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying movie reviews using TextBlob...\n",
      "\n",
      "First 5 rows with the new TextBlob_Sentiment column:\n",
      "                                              review  sentiment  \\\n",
      "0  With all this stuff going down at the moment w...          1   \n",
      "1  \\The Classic War of the Worlds\\\" by Timothy Hi...          1   \n",
      "2  The film starts with a manager (Nicholas Bell)...          0   \n",
      "3  It must be assumed that those who praised this...          0   \n",
      "4  Superbly trashy and wondrously unpretentious 8...          1   \n",
      "\n",
      "  TextBlob_Sentiment  \n",
      "0           Positive  \n",
      "1           Positive  \n",
      "2           Negative  \n",
      "3           Positive  \n",
      "4           Negative  \n",
      "\n",
      "--- Summary of TextBlob Sentiment Classification ---\n",
      "TextBlob_Sentiment\n",
      "Positive    19017\n",
      "Negative     5983\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- TextBlob Sentiment Analysis ---\n",
    "\n",
    "# Analyzes the sentiment of a given text using TextBlob. Returns 'Positive' if polarity >= 0, otherwise 'Negative'.\n",
    "def get_textblob_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity >= 0:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "# Apply the sentiment analysis function to the 'review' column\n",
    "print(\"Classifying movie reviews using TextBlob...\")\n",
    "df['TextBlob_Sentiment'] = df['review'].apply(get_textblob_sentiment)\n",
    "\n",
    "# Display Results\n",
    "print(\"\\nFirst 5 rows with the new TextBlob_Sentiment column:\")\n",
    "print(df[['review', 'sentiment', 'TextBlob_Sentiment']].head())\n",
    "print(\"\\n--- Summary of TextBlob Sentiment Classification ---\")\n",
    "print(df['TextBlob_Sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d26b1e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Accuracy ---\n",
      "The accuracy of the TextBlob model is: 0.69\n"
     ]
    }
   ],
   "source": [
    "# --- TextBlob Accuracy Calculation ---\n",
    "\n",
    "# Map the original numerical sentiment to text labels for comparison\n",
    "df['true_sentiment_text'] = df['sentiment'].map({1: 'Positive', 0: 'Negative'})\n",
    "\n",
    "# Calculate the accuracy by comparing the true labels to TextBlob's predictions\n",
    "accuracy = accuracy_score(df['true_sentiment_text'], df['TextBlob_Sentiment'])\n",
    "\n",
    "# Display Results\n",
    "\n",
    "print(\"\\n--- Model Accuracy ---\")\n",
    "print(f\"The accuracy of the TextBlob model is: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eacbfc9",
   "metadata": {},
   "source": [
    "### Conclusion and Analysis for TextBlob\n",
    "\n",
    "The model's accuracy is calculated by comparing the sentiment predicted by TextBlob with the true sentiment labels provided in the dataset. Since the dataset is perfectly balanced with 12,500 positive and 12,500 negative reviews, a random guess would have an expected accuracy of 50%. The TextBlob model, leveraging a pre-trained sentiment lexicon, perform much better than this baseline. It's accuracy was 69% (0.69)\n",
    "\n",
    "Therefore, the TextBlob model is significantly better than random guessing. Its accuracy, as you will see from the script's output, will be a good indicator of its effectiveness in classifying movie review sentiment without any prior training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c3486da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/surenther/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the VADER lexicon\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a2bd211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying movie reviews using VADER...\n",
      "\n",
      "--- Model Accuracy ---\n",
      "The accuracy of the VADER model is: 0.69\n"
     ]
    }
   ],
   "source": [
    "# --- VADER Sentiment Analysis ---\n",
    "\n",
    "# Analyzes the sentiment of a given text using VADER. Returns 'Positive' if polarity >= 0, otherwise 'Negative'.\n",
    "def get_vader_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of a given text using VADER.\n",
    "    Returns 'Positive' if compound score > 0, otherwise 'Negative'.\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    compound_score = analyzer.polarity_scores(text)['compound']\n",
    "    if compound_score > 0:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "# Apply the sentiment analysis function to the 'review' column\n",
    "print(\"Classifying movie reviews using VADER...\")\n",
    "df['VADER_Sentiment'] = df['review'].apply(get_vader_sentiment)\n",
    "\n",
    "# Map the original numerical sentiment to text labels for comparison\n",
    "df['true_sentiment_text'] = df['sentiment'].map({1: 'Positive', 0: 'Negative'})\n",
    "\n",
    "# Calculate the accuracy by comparing the true labels to VADER's predictions\n",
    "accuracy = accuracy_score(df['true_sentiment_text'], df['VADER_Sentiment'])\n",
    "\n",
    "# --- Display Results ---\n",
    "print(\"\\n--- Model Accuracy ---\")\n",
    "print(f\"The accuracy of the VADER model is: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd5dd5",
   "metadata": {},
   "source": [
    "### Conclusion and Analysis for VADER\n",
    "The VADER model, a lexicon and rule-based sentiment analyzer, achieved an accuracy of 69% in classifying the movie reviews. This is significantly better than a random guess, which would yield an accuracy of 50% on this balanced dataset. The model's performance demonstrates its effectiveness in identifying sentiment in text, even without being explicitly trained on this movie review data. However, it's worth noting that its accuracy of 0.69 suggests that it still has limitations in handling the nuances of natural language, such as sarcasm, complex sentence structures, or domain-specific terminology that might differ from its pre-built lexicon. Overall, VADER provides a fast and solid baseline for sentiment analysis, but its performance could likely be surpassed by more sophisticated machine-learning models like those in the Hugging Face Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "201d68e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing and stemming complete.\n",
      "\n",
      "First 5 stemmed reviews:\n",
      "0    stuff go moment mj ive start listen music watc...\n",
      "1    classic war world timothi hine entertain film ...\n",
      "2    film start manag nichola bell give welcom inve...\n",
      "3    must assum prais film greatest film opera ever...\n",
      "4    superbl trashi wondrous unpretenti 80 exploit ...\n",
      "Name: stemmed_review, dtype: object\n",
      "\n",
      "Creating Bag-of-Words matrix...\n",
      "Bag-of-Words matrix dimensions: (25000, 112735)\n",
      "\n",
      "Creating TF-IDF matrix...\n",
      "TF-IDF matrix dimensions: (25000, 112735)\n",
      "\n",
      "Verified: Number of rows in matrices match original DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Download the stopwords list if not already available\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK stopwords...\")\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "# Define a function for text cleaning and stemming\n",
    "def clean_and_stem_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove HTML tags (common in this dataset)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove punctuation and special characters, keeping only letters and numbers\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    # Tokenize the text and remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    cleaned_words = [word for word in words if word not in stop_words]\n",
    "    # Apply PorterStemmer\n",
    "    porter = PorterStemmer()\n",
    "    stemmed_words = [porter.stem(word) for word in cleaned_words]\n",
    "    # Join the words back into a single string\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Apply the cleaning and stemming function\n",
    "df['stemmed_review'] = df['review'].apply(clean_and_stem_text)\n",
    "\n",
    "print(\"Text preprocessing and stemming complete.\")\n",
    "print(\"\\nFirst 5 stemmed reviews:\")\n",
    "print(df['stemmed_review'].head())\n",
    "\n",
    "# --- Vectorization ---\n",
    "\n",
    "# Create a Bag-of-Words matrix\n",
    "print(\"\\nCreating Bag-of-Words matrix...\")\n",
    "count_vectorizer = CountVectorizer()\n",
    "bag_of_words_matrix = count_vectorizer.fit_transform(df['stemmed_review'])\n",
    "\n",
    "print(f\"Bag-of-Words matrix dimensions: {bag_of_words_matrix.shape}\")\n",
    "\n",
    "# Create a TF-IDF matrix\n",
    "print(\"\\nCreating TF-IDF matrix...\")\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['stemmed_review'])\n",
    "\n",
    "print(f\"TF-IDF matrix dimensions: {tfidf_matrix.shape}\")\n",
    "\n",
    "# Verify dimensions\n",
    "if bag_of_words_matrix.shape[0] == df.shape[0] and tfidf_matrix.shape[0] == df.shape[0]:\n",
    "    print(\"\\nVerified: Number of rows in matrices match original DataFrame.\")\n",
    "else:\n",
    "    print(\"\\nWarning: Number of rows in matrices do not match original DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844afadc",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Based on the output, the data preprocessing steps were successful. The Bag-of-Words and TF-IDF matrices were created, and their dimensions, (25000, 112735), confirm that the number of rows matches the original dataset, with 112,735 unique stemmed words serving as features.\n",
    "\n",
    "Combining this with our earlier findings from the VADER and TextBlob analyses (both with an accuracy of 0.69), we can draw a cohesive conclusion. The lexicon-based models provided a respectable baseline, outperforming a random guess, but they demonstrated the limitations of their rule-based approach. The successful creation of the Bag-of-Words and TF-IDF matrices now provides a solid foundation for building a custom, machine learning model. These matrices are a numerical representation of the text, which is the required input for more advanced classifiers (e.g., Logistic Regression, Support Vector Machines) that can learn from the data itself. By using these matrices, we can now attempt to create a model that learns the nuances of the movie review language, potentially leading to a much higher accuracy than the pre-built lexicon-based analyzers.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
